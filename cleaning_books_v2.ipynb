{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "import re\n",
    "from dateutil.parser import parse\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating auxiliary function\n",
    "def export_json(data, filename):    \n",
    "    with open(f'./output/{filename}.json', 'w') as f:\n",
    "        json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of dataset\n",
      "Index(['bookId', 'title', 'series', 'author', 'rating', 'isbn', 'genres',\n",
      "       'pages', 'publishDate', 'firstPublishDate', 'awards', 'numRatings',\n",
      "       'ratingsByStars'],\n",
      "      dtype='object')\n",
      "-> Lenght before removing books without ISBN: 52478\n",
      "-> Lenght after removing books without ISBN: 48124\n",
      "-> Lenght before filtering 0.5 best books: 48124\n",
      "-> Lenght after filtering 0.5 best books: 24060\n",
      "-> Lenght before filtering by weird number of pages: 24060\n",
      "-> Lenght after filtering by weird number of pages: 23711\n"
     ]
    }
   ],
   "source": [
    "# Importing the data\n",
    "df_books = pd.read_csv('best_books_goodreads.csv', dtype={'awards':object})\n",
    "\n",
    "# Dropping unnecessary columns\n",
    "df_books.drop(columns=['description', 'language', 'characters', 'bookFormat','edition','publisher','likedPercent',\n",
    "                        'setting', 'coverImg', 'bbeScore', 'bbeVotes', 'price'], inplace=True)\n",
    "\n",
    "print('Columns of dataset')\n",
    "print(df_books.columns)\n",
    "\n",
    "# Removing books without ISBN\n",
    "print('-> Lenght before removing books without ISBN:',len(df_books))\n",
    "df_books = df_books[df_books['isbn']!= '9999999999999']\n",
    "print('-> Lenght after removing books without ISBN:',len(df_books))\n",
    "\n",
    "# Removing books with low quantity of ratings\n",
    "median_num_ratings = df_books['numRatings'].fillna(value=0).astype(int).quantile(0.5)\n",
    "print(\"-> Lenght before filtering 0.5 best books:\", len(df_books))\n",
    "df_books = df_books[df_books['numRatings'] > median_num_ratings].copy()\n",
    "print(\"-> Lenght after filtering 0.5 best books:\", len(df_books))\n",
    "\n",
    "# Removing books with weird or uncommon page counts\n",
    "print(\"-> Lenght before filtering by weird number of pages:\", len(df_books))\n",
    "df_books = df_books[df_books['pages']!='1 page'] # '1 page' error\n",
    "df_books = df_books[~df_books['pages'].isna()] # NA error\n",
    "df_books = df_books[df_books['pages'] != 0] # Books with 0 pages\n",
    "min_num_of_pages = 10\n",
    "max_num_of_pages = 2000 \n",
    "df_books['pages'] = df_books['pages'].astype(int)\n",
    "df_books = df_books[df_books['pages'] < max_num_of_pages] # Removing books with less than 10 pages\n",
    "df_books = df_books[df_books['pages'] > min_num_of_pages] # Removing books with more than 2000 pages\n",
    "print(\"-> Lenght after filtering by weird number of pages:\",len(df_books))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publishDate</th>\n",
       "      <th>firstPublishDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09/14/08</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09/28/04</td>\n",
       "      <td>06/21/03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09/06/06</td>\n",
       "      <td>10/05/05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>03/14/06</td>\n",
       "      <td>09/01/05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>04/28/96</td>\n",
       "      <td>08/17/45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52453</th>\n",
       "      <td>October 1st 1991</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52461</th>\n",
       "      <td>September 19th 2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52463</th>\n",
       "      <td>October 1st 2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52469</th>\n",
       "      <td>January 1st 1984</td>\n",
       "      <td>May 1st 1976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52475</th>\n",
       "      <td>March 18th 2011</td>\n",
       "      <td>March 15th 2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23711 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               publishDate firstPublishDate\n",
       "0                 09/14/08              NaN\n",
       "1                 09/28/04         06/21/03\n",
       "4                 09/06/06         10/05/05\n",
       "5                 03/14/06         09/01/05\n",
       "6                 04/28/96         08/17/45\n",
       "...                    ...              ...\n",
       "52453     October 1st 1991             1991\n",
       "52461  September 19th 2014              NaN\n",
       "52463     October 1st 2015              NaN\n",
       "52469     January 1st 1984     May 1st 1976\n",
       "52475      March 18th 2011  March 15th 2011\n",
       "\n",
       "[23711 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_books[['publishDate', 'firstPublishDate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Lenght before filtering null or weird dates: 23711\n",
      "-> Lenght after filtering null or weird dates: 22972\n"
     ]
    }
   ],
   "source": [
    "# Function to clean date\n",
    "def clean_date(date_str):\n",
    "    try:\n",
    "        # If the date contains only a year, returns None\n",
    "        if re.match(r'^\\d{4}$', date_str):\n",
    "            return None\n",
    "        \n",
    "        # If the date is in MM/DD/YY format\n",
    "        if re.match(r'\\d{2}/\\d{2}/\\d{2}', date_str):\n",
    "            parsed_date = pd.to_datetime(date_str, format='%m/%d/%y')\n",
    "        else:\n",
    "            # If the date is in a text format, use the date parser\n",
    "            parsed_date = parse(date_str)\n",
    "        \n",
    "        # If the result date is after than 2020, correct it to 19XX\n",
    "        if parsed_date >= datetime.strptime('2021-01-01', '%Y-%m-%d'):\n",
    "            parsed_date = parsed_date.replace(year=parsed_date.year - 100)\n",
    "        \n",
    "        # Returns date in YYYY-MM-DD format\n",
    "        return parsed_date.strftime('%Y-%m-%d')\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "df_books['best_publish_date'] = df_books['firstPublishDate'].fillna(df_books['publishDate'])\n",
    "\n",
    "# Apply the function to the 'dirty_date' column\n",
    "df_books['clean_date'] = df_books['best_publish_date'].apply(clean_date)\n",
    "\n",
    "# Removes books with no publishing date\n",
    "print(\"-> Lenght before filtering null or weird dates:\",len(df_books))\n",
    "df_books = df_books[~df_books['clean_date'].isna()]\n",
    "\n",
    "# Removes books with weird date\n",
    "df_books = df_books[df_books['clean_date']!='0458-09-24']\n",
    "print(\"-> Lenght after filtering null or weird dates:\",len(df_books))\n",
    "\n",
    "# Calculates day of the week and month based on publishing date\n",
    "df_books['clean_date'] = pd.to_datetime(df_books['clean_date'])\n",
    "df_books['day_of_week'] = df_books['clean_date'].dt.day_name().astype(str)\n",
    "df_books['month_name'] = df_books['clean_date'].dt.month_name().astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting the genres column\n",
    "df_books['genres'] = df_books['genres'].apply(literal_eval)\n",
    "\n",
    "# Filtering the genre with a hand tailored list\n",
    "valid_genres = ['Fiction', 'Nonfiction', 'Mystery', 'Fantasy', 'Science Fiction', 'Romance', 'Biography', 'Historical Fiction', 'Young Adult', 'Childrens', 'Self Help', 'Horror', 'Classics', 'Poetry', 'Graphic Novels', 'Adventure', 'True Crime', 'Religion', 'Science', 'Business']\n",
    "df_books['valid_genres'] = df_books['genres'].apply(lambda x: [item for item in x if item in valid_genres])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating success metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating normalized rating column\n",
    "df_books['norm_rating'] = df_books['rating']/5\n",
    "\n",
    "# Calculating number of awards per book\n",
    "df_books['awards'] = df_books['awards'].apply(literal_eval)\n",
    "df_books['num_awards'] = df_books['awards'].apply(len)\n",
    "\n",
    "# Creating normalized number of awards column\n",
    "max_num_awards = max(df_books['num_awards'])\n",
    "df_books['norm_num_awards'] = df_books['num_awards']/max_num_awards\n",
    "\n",
    "# Creating normalized number of ratings column\n",
    "max_num_ratings = max(df_books['numRatings'])\n",
    "df_books['norm_num_ratings'] = df_books['numRatings']/max_num_ratings\n",
    "\n",
    "# Defining the weights for a general success metric\n",
    "weights = {\n",
    "    'avg_rating': 1,\n",
    "    'num_awards': 2,\n",
    "    'num_ratings': 1\n",
    "}\n",
    "\n",
    "# Calculating the success rate\n",
    "df_books['success_rate'] = (df_books['norm_num_awards']*weights['num_awards']+\\\n",
    "                           df_books['norm_num_ratings']*weights['num_ratings']+\\\n",
    "                           df_books['norm_rating']*weights['avg_rating'])/sum(weights.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating auxiliary objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Success metrics by number of pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the average success rate by number of pages\n",
    "success_by_num_pages = df_books.groupby('pages').agg({\n",
    "    'success_rate':'mean',\n",
    "    'norm_rating':'mean',\n",
    "    'norm_num_awards':'mean',\n",
    "    'norm_num_ratings':'mean',\n",
    "    })\n",
    "\n",
    "success_by_num_pages.to_csv('output/num_pages_analysis/sucess_by_num_of_pages.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of books by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating and exporting number of books by date\n",
    "num_book_by_date = df_books.groupby('clean_date').agg({'bookId': 'count'})\n",
    "num_book_by_date.rename(columns={'bookId': 'num_of_books'}, inplace=True)\n",
    "num_book_by_date.to_csv('./output/num_books_by_time/num_book_by_date.csv')\n",
    "\n",
    "# Calculating and exporting number of books by day of week\n",
    "num_book_by_day_of_week = df_books.groupby('day_of_week').agg({'bookId': 'count'})\n",
    "num_book_by_day_of_week.rename(columns={'bookId': 'num_of_books'}, inplace=True)\n",
    "num_book_by_day_of_week.to_csv('./output/num_books_by_time/num_book_by_day_of_week.csv')\n",
    "\n",
    "# Calculating and exporting number of books by month name\n",
    "num_book_by_month = df_books.groupby('month_name').agg({'bookId': 'count'})\n",
    "num_book_by_month.rename(columns={'bookId': 'num_of_books'}, inplace=True)\n",
    "new_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "num_book_by_month = num_book_by_month.reindex(new_order, axis=0)\n",
    "num_book_by_month.to_csv('./output/num_books_by_time/num_book_by_month.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Books and book count by genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the books for each genre\n",
    "genre_dict = defaultdict(list)\n",
    "for index, row in df_books.iterrows():\n",
    "    book_name = row['bookId']\n",
    "    genres = row['valid_genres']\n",
    "    for genre in genres:\n",
    "        genre_dict[genre].append(book_name)\n",
    "\n",
    "books_by_genre_dict = dict(genre_dict)\n",
    "\n",
    "# Get the number of books for each genre and sort it\n",
    "genre_count = {k: len(v) for k, v in books_by_genre_dict.items()}\n",
    "genre_count = {k: v for k, v in sorted(genre_count.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# Saving number of books for each genre and books by genre\n",
    "export_json(genre_count, 'genres/num_books_by_genre')\n",
    "export_json(books_by_genre_dict, 'genres/books_by_genre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating object with genres co-occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize nested defaultdict for counting co-occurrences\n",
    "co_occurrence = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Count co-occurrences for each genre combination\n",
    "for genre1 in books_by_genre_dict:\n",
    "    for genre2 in books_by_genre_dict:\n",
    "        if genre1 == genre2:\n",
    "            continue\n",
    "        common_books = set(books_by_genre_dict[genre1]) & set(books_by_genre_dict[genre2])\n",
    "        co_occurrence[genre1][genre2] = len(common_books)\n",
    "\n",
    "# Convert nested defaultdict to regular dict\n",
    "co_occurrence = {k: dict(v) for k, v in co_occurrence.items()}\n",
    "\n",
    "# Saving co-occurence counts\n",
    "export_json(co_occurrence, 'genres/cooccurences_2_by_2_genre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting trends in series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataframe with books that are series only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating columns with the name and position in series\n",
    "df_series = (df_books[~df_books['series'].isna()]).copy()\n",
    "df_series['name_of_series'] = df_series['series'].str.split(pat='#', expand=True)[0]\n",
    "df_series['num_in_series'] = df_series['series'].str.split(pat='#', expand=True)[1]\n",
    "# df_series.head(3)\n",
    "\n",
    "# Filtering for coherent series numbers (from 1 to 20)\n",
    "valid_series = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20']\n",
    "df_series = df_series[df_series['num_in_series'].isin(valid_series)].copy()\n",
    "df_series['num_in_series'] = df_series['num_in_series'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating auxiliary objects for the series dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating and exporting success rates by number in series\n",
    "sucess_by_num_in_series = df_series.groupby('num_in_series', as_index=True).agg({\n",
    "    'success_rate':'mean',\n",
    "    'norm_rating':'mean',\n",
    "    'norm_num_awards':'mean',\n",
    "    'norm_num_ratings':'mean',\n",
    "})\n",
    "sucess_by_num_in_series.to_csv('./output/series_analysis/sucess_by_num_in_series.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting final dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.to_csv('output/output_dfs/clean_books.csv', index=False)\n",
    "df_series.to_csv('output/output_dfs/series_books.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tecnico_sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
